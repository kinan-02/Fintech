{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kinan-02/Fintech/blob/main/eval_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip final_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCz4e02PhIVC",
        "outputId": "452d01ed-1a37-4136-a11e-ecef5b8414af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  final_data.zip\n",
            "  inflating: final_data.parquet      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "# Load the Parquet file\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)  # Set a fixed seed for CPU\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(0)  # Set seed for all CUDA devices\n",
        "    torch.cuda.manual_seed_all(0)  # If you are using multiple GPUs\n",
        "\n",
        "# If you're using cudnn backend for performance improvements, you should set the following to ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "df = pd.read_parquet('final_data.parquet')\n",
        "df_test = pd.read_parquet('test_data.parquet')\n",
        "\n",
        "# Define features and target (next-minute close price of Bitcoin)\n",
        "features = df[['open_btc', 'high_btc', 'low_btc', 'trade_count_btc',\n",
        "               'open_eth', 'high_eth', 'low_eth', 'close_eth', 'trade_count_eth',\n",
        "               'open_cl', 'close_cl', 'high_cl', 'low_cl', 'trade_count_cl',\n",
        "               'open_gold', 'close_gold', 'high_gold', 'low_gold', 'trade_count_gold',\n",
        "               'open_uup', 'close_uup', 'high_uup', 'low_uup', 'trade_count_uup',\n",
        "               'open_mstr', 'close_mstr', 'high_mstr', 'low_mstr', 'trade_count_mstr',\n",
        "               'open_spy', 'close_spy', 'high_spy', 'low_spy', 'trade_count_spy',\n",
        "               'open_ndaq', 'close_ndaq', 'high_ndaq', 'low_ndaq', 'trade_count_ndaq']]\n",
        "\n",
        "test_features = df_test[['open_btc', 'high_btc', 'low_btc', 'trade_count_btc',\n",
        "               'open_eth', 'high_eth', 'low_eth', 'close_eth', 'trade_count_eth',\n",
        "               'open_cl', 'close_cl', 'high_cl', 'low_cl', 'trade_count_cl',\n",
        "               'open_gold', 'close_gold', 'high_gold', 'low_gold', 'trade_count_gold',\n",
        "               'open_uup', 'close_uup', 'high_uup', 'low_uup', 'trade_count_uup',\n",
        "               'open_mstr', 'close_mstr', 'high_mstr', 'low_mstr', 'trade_count_mstr',\n",
        "               'open_spy', 'close_spy', 'high_spy', 'low_spy', 'trade_count_spy',\n",
        "               'open_ndaq', 'close_ndaq', 'high_ndaq', 'low_ndaq', 'trade_count_ndaq']]\n",
        "\n",
        "# Target: next-minute close price of Bitcoin\n",
        "target = df['close_btc'].shift(-1)  # Shift by -1 to predict next-minute close price\n",
        "target_test = df_test['close_btc']\n",
        "\n",
        "# Drop the last row (since it doesn't have a valid target)\n",
        "features = features[:-1]\n",
        "target = target[:-1]\n",
        "test_features = test_features[:-1]\n",
        "target_test = target_test[:-1]\n",
        "\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler()\n",
        "features = scaler.fit_transform(features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Manually split into training (first 80%) and testing (last 20%) without shuffling\n",
        "# split_index = int(0.8 * len(features))\n",
        "\n",
        "# X_train, X_test = features[:split_index], features[split_index:]\n",
        "# y_train, y_test = target[:split_index], target[split_index:]\n",
        "\n",
        "X_train, X_test = features, test_features\n",
        "y_train, y_test = target, target_test\n",
        "\n",
        "# Convert to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "# Create DataLoader for training data\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Create DataLoader for test data (optional for evaluation)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the Model (Use the trained model as an argument)\n",
        "def calculate_var(returns, confidence_level=90):\n",
        "    \"\"\"\n",
        "    Calculate Value at Risk (VaR) for a given set of returns and confidence level.\n",
        "    \"\"\"\n",
        "    return np.percentile(returns, 100 - confidence_level)\n",
        "\n",
        "\n",
        "def evaluate_model(model):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    total_loss = 0\n",
        "    total_percentage_loss = 0  # To track percentage loss\n",
        "    total_mape = 0  # To track MAPE\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            output = model(X_batch)\n",
        "            loss = loss_fn(output, y_batch)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate loss as a percentage (relative error)\n",
        "            percentage_loss = torch.sqrt(loss) / (torch.mean(y_batch) + 1e-10) * 100\n",
        "            total_percentage_loss += percentage_loss.item()\n",
        "\n",
        "            # Calculate Mean Absolute Percentage Error (MAPE)\n",
        "            mape = torch.mean(torch.abs((y_batch - output) / (y_batch + 1e-10))) * 100\n",
        "            total_mape += mape.item()\n",
        "\n",
        "            predictions.append(output.numpy())\n",
        "            actuals.append(y_batch.numpy())\n",
        "\n",
        "    # Calculate the predicted returns and real returns\n",
        "    predictions[-1] = np.repeat(predictions[-1], 32)\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    actuals = np.concatenate(actuals, axis=0)\n",
        "\n",
        "    # Calculate returns as percentage change between consecutive predictions\n",
        "    predicted_returns = (predictions[1:] - predictions[:-1]) / predictions[:-1]\n",
        "    real_returns = (actuals[1:] - actuals[:-1]) / actuals[:-1]\n",
        "\n",
        "    # Calculate predicted VaR and real VaR at 95% confidence level\n",
        "    predicted_var = calculate_var(predicted_returns, confidence_level=90)\n",
        "    real_var = calculate_var(real_returns, confidence_level=90)\n",
        "\n",
        "    print(f\"Test Loss: {total_loss / len(test_loader):.6f}\")\n",
        "    print(f\"Test Loss as Percentage: {total_percentage_loss / len(test_loader):.2f}%\")\n",
        "    print(f\"Predicted VaR (95% confidence): {predicted_var}\")\n",
        "    print(f\"Real VaR (95% confidence): {real_var}\")\n",
        "    print(f\"Mean Absolute Percentage Error (MAPE): {total_mape / len(test_loader):.2f}%\")\n",
        "    return predictions, actuals"
      ],
      "metadata": {
        "id": "Pa46lHqcA1uu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7nemCzzg_tev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BaseLine (LSTM) Model Eval"
      ],
      "metadata": {
        "id": "qnuRFg3R_wZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, n_layers, tr_layers, n_heads_first, n_heads_second, input_dim, hidden_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.tr_layers = tr_layers\n",
        "        self.n_heads_first = n_heads_first\n",
        "        self.n_heads_second = n_heads_second\n",
        "\n",
        "        self.weight_lstm = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        self.weight_transform = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        self.weight_transform2 = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        # self.weight_attn = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "\n",
        "        # Initial fully connected layers to project input features\n",
        "        self.input_fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim * 2),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_dim * 2, hidden_dim),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # LSTM layers\n",
        "        self.main_task = nn.LSTM(input_size=hidden_dim,\n",
        "                                 hidden_size=hidden_dim,\n",
        "                                 batch_first=True,\n",
        "                                 num_layers=n_layers,\n",
        "                                 dropout=dropout)\n",
        "\n",
        "        self.last_task = nn.LSTM(input_size=hidden_dim,\n",
        "                                 hidden_size=hidden_dim,\n",
        "                                 batch_first=True,\n",
        "                                 num_layers=n_layers,\n",
        "                                 dropout=dropout)\n",
        "\n",
        "        # Transformer layers\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=self.n_heads_first,\n",
        "                                                        dim_feedforward=hidden_dim * 4,\n",
        "                                                        dropout=dropout,\n",
        "                                                        activation='relu',\n",
        "                                                        batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=self.tr_layers)\n",
        "\n",
        "        self.encoder_layer2 = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=self.n_heads_second,\n",
        "                                                         dim_feedforward=hidden_dim,\n",
        "                                                         dropout=dropout,\n",
        "                                                         activation='relu',\n",
        "                                                         batch_first=True)\n",
        "        self.transformer2 = nn.TransformerEncoder(self.encoder_layer2, num_layers=self.tr_layers)\n",
        "\n",
        "        # Final fully connected layer to project to output (next-minute close price)\n",
        "        self.output_fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 2, output_dim)\n",
        "        )\n",
        "\n",
        "\n",
        "    def generate_mask(self, size):\n",
        "        \"\"\"\n",
        "        Generate a causal mask for the Transformer, preventing future positions from attending to earlier positions.\n",
        "        \"\"\"\n",
        "        mask = torch.triu(torch.ones(size, size) * float('-inf'), diagonal=1)\n",
        "        return mask\n",
        "\n",
        "    def forward(self, input_vec):\n",
        "        # Pass through input FC layers\n",
        "        lstm_input = self.input_fc(input_vec)\n",
        "        # LSTM layer\n",
        "        final_output, _ = self.main_task(lstm_input)\n",
        "\n",
        "\n",
        "        # Output layer for the predicted close price\n",
        "        output = self.output_fc(final_output)\n",
        "\n",
        "        return output.squeeze()"
      ],
      "metadata": {
        "id": "Jb0NhpXz_14M"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model structure\n",
        "model = LSTM(\n",
        "        n_layers=1, tr_layers=1, n_heads_first=4, n_heads_second=1,\n",
        "        input_dim=X_train.shape[1], hidden_dim=32, output_dim=1, dropout=0\n",
        "    )\n",
        "\n",
        "# Load the saved state dictionary into the model\n",
        "model.load_state_dict(torch.load('baseline.pth'))\n",
        "\n",
        "baseline_pred,actuals = evaluate_model(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYi9tWLFAXM8",
        "outputId": "3cc750a9-bbea-460e-c52a-c5e1db23c97a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "<ipython-input-36-4b34d78c95ea>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('baseline.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4162.417426\n",
            "Test Loss as Percentage: 0.09%\n",
            "Predicted VaR (95% confidence): -0.0008045249851420522\n",
            "Real VaR (95% confidence): -0.0006554247112944722\n",
            "Mean Absolute Percentage Error (MAPE): 0.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer Model Eval"
      ],
      "metadata": {
        "id": "KX_svI2i_lmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Model Definition\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, n_layers, tr_layers, n_heads_first, n_heads_second, input_dim, hidden_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.tr_layers = tr_layers\n",
        "        self.n_heads_first = n_heads_first\n",
        "        self.n_heads_second = n_heads_second\n",
        "\n",
        "        self.weight_lstm = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        self.weight_transform = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        self.weight_transform2 = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        self.weight_attn = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "\n",
        "        # Initial fully connected layers to project input features\n",
        "        self.input_fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim * 2),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_dim * 2, hidden_dim),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # LSTM layers\n",
        "        self.main_task = nn.LSTM(input_size=hidden_dim,\n",
        "                                 hidden_size=hidden_dim,\n",
        "                                 batch_first=True,\n",
        "                                 num_layers=n_layers,\n",
        "                                 dropout=dropout)\n",
        "\n",
        "        self.last_task = nn.LSTM(input_size=hidden_dim,\n",
        "                                 hidden_size=hidden_dim,\n",
        "                                 batch_first=True,\n",
        "                                 num_layers=n_layers,\n",
        "                                 dropout=dropout)\n",
        "\n",
        "        # Transformer layers\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=self.n_heads_first,\n",
        "                                                        dim_feedforward=hidden_dim * 4,\n",
        "                                                        dropout=dropout,\n",
        "                                                        activation='relu',\n",
        "                                                        batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=self.tr_layers)\n",
        "\n",
        "        self.encoder_layer2 = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=self.n_heads_second,\n",
        "                                                         dim_feedforward=hidden_dim,\n",
        "                                                         dropout=dropout,\n",
        "                                                         activation='relu',\n",
        "                                                         batch_first=True)\n",
        "        self.transformer2 = nn.TransformerEncoder(self.encoder_layer2, num_layers=self.tr_layers)\n",
        "\n",
        "        # Final fully connected layer to project to output (next-minute close price)\n",
        "        self.output_fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 2, output_dim)\n",
        "        )\n",
        "\n",
        "    def generate_mask(self, size):\n",
        "        \"\"\"\n",
        "        Generate a causal mask for the Transformer, preventing future positions from attending to earlier positions.\n",
        "        \"\"\"\n",
        "        mask = torch.triu(torch.ones(size, size) * float('-inf'), diagonal=1)\n",
        "        return mask\n",
        "\n",
        "    def forward(self, input_vec):\n",
        "        # Pass through input FC layers\n",
        "        lstm_input = self.input_fc(input_vec)\n",
        "\n",
        "        # Generate mask for Transformer based on sequence length\n",
        "        seq_len,a = input_vec.size()\n",
        "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)  # Upper triangular mask\n",
        "        mask = mask.masked_fill(mask == 1, float('-inf'))  # Replace 1s with -inf for masking\n",
        "        transformer_output = self.transformer(lstm_input, mask=mask)\n",
        "\n",
        "        # Output layer for the predicted close price\n",
        "        output = self.output_fc(transformer_output)\n",
        "\n",
        "        return output.squeeze()  # Ensure output shape is correct\n",
        "\n"
      ],
      "metadata": {
        "id": "tcEN2qXzk3rB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model structure\n",
        "model = Transformer(\n",
        "        n_layers=1, tr_layers=1, n_heads_first=4, n_heads_second=1,\n",
        "        input_dim=X_train.shape[1], hidden_dim=32, output_dim=1, dropout=0\n",
        "    )\n",
        "\n",
        "# Load the saved state dictionary into the model\n",
        "model.load_state_dict(torch.load('transformer_model.pth'))\n",
        "\n",
        "transformer_pred,actuals = evaluate_model(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWsOBYcA_C2f",
        "outputId": "84025621-969e-4159-8c61-9b7cba4a3ef1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-c3efeabe3af4>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('transformer_model.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1968.874631\n",
            "Test Loss as Percentage: 0.06%\n",
            "Predicted VaR (95% confidence): -0.0006499371374957263\n",
            "Real VaR (95% confidence): -0.0006554247112944722\n",
            "Mean Absolute Percentage Error (MAPE): 0.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer-LSTM Model Eval"
      ],
      "metadata": {
        "id": "A-XaF2YXBSTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer_LSTM(nn.Module):\n",
        "    def __init__(self, n_layers, tr_layers, n_heads_first, n_heads_second, input_dim, hidden_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.tr_layers = tr_layers\n",
        "        self.n_heads_first = n_heads_first\n",
        "        self.n_heads_second = n_heads_second\n",
        "\n",
        "        self.weight_lstm = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        self.weight_transform = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        self.weight_transform2 = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        # self.weight_attn = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "\n",
        "        # Initial fully connected layers to project input features\n",
        "        self.input_fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim * 2),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_dim * 2, hidden_dim),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # LSTM layers\n",
        "        self.main_task = nn.LSTM(input_size=hidden_dim,\n",
        "                                 hidden_size=hidden_dim,\n",
        "                                 batch_first=True,\n",
        "                                 num_layers=n_layers,\n",
        "                                 dropout=dropout)\n",
        "\n",
        "        self.last_task = nn.LSTM(input_size=hidden_dim,\n",
        "                                 hidden_size=hidden_dim,\n",
        "                                 batch_first=True,\n",
        "                                 num_layers=n_layers,\n",
        "                                 dropout=dropout)\n",
        "\n",
        "        # Transformer layers\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=self.n_heads_first,\n",
        "                                                        dim_feedforward=hidden_dim * 4,\n",
        "                                                        dropout=dropout,\n",
        "                                                        activation='relu',\n",
        "                                                        batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=self.tr_layers)\n",
        "\n",
        "        self.encoder_layer2 = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=self.n_heads_second,\n",
        "                                                         dim_feedforward=hidden_dim,\n",
        "                                                         dropout=dropout,\n",
        "                                                         activation='relu',\n",
        "                                                         batch_first=True)\n",
        "        self.transformer2 = nn.TransformerEncoder(self.encoder_layer2, num_layers=self.tr_layers)\n",
        "\n",
        "        # Final fully connected layer to project to output (next-minute close price)\n",
        "        self.output_fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 2, output_dim)\n",
        "        )\n",
        "\n",
        "    def generate_mask(self, size):\n",
        "        \"\"\"\n",
        "        Generate a causal mask for the Transformer, preventing future positions from attending to earlier positions.\n",
        "        \"\"\"\n",
        "        mask = torch.triu(torch.ones(size, size) * float('-inf'), diagonal=1)\n",
        "        return mask\n",
        "\n",
        "    def forward(self, input_vec):\n",
        "        # Pass through input FC layers\n",
        "        lstm_input = self.input_fc(input_vec)\n",
        "\n",
        "        # Generate mask for Transformer based on sequence length\n",
        "        seq_len,a = input_vec.size()\n",
        "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)  # Upper triangular mask\n",
        "        mask = mask.masked_fill(mask == 1, float('-inf'))  # Replace 1s with -inf for masking\n",
        "        transformer_output1 = self.transformer(lstm_input, mask=mask)\n",
        "        # LSTM layer\n",
        "        lstm_output, _ = self.main_task(transformer_output1)\n",
        "\n",
        "        # Output layer for the predicted close price\n",
        "        output = self.output_fc(lstm_output)\n",
        "\n",
        "        return output.squeeze()"
      ],
      "metadata": {
        "id": "BOziPlyY_kSs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model structure\n",
        "model = Transformer_LSTM(\n",
        "        n_layers=1, tr_layers=1, n_heads_first=4, n_heads_second=1,\n",
        "        input_dim=X_train.shape[1], hidden_dim=32, output_dim=1, dropout=0\n",
        "    )\n",
        "\n",
        "# Load the saved state dictionary into the model\n",
        "model.load_state_dict(torch.load('transformer_lstm.pth'))\n",
        "\n",
        "transformer_lstm_pred,actuals = evaluate_model(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRjtQbgkBx34",
        "outputId": "6f890ae2-5046-4a1e-abdc-e93469d81d1d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "<ipython-input-42-4747df1fc193>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('transformer_lstm.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3007.021862\n",
            "Test Loss as Percentage: 0.08%\n",
            "Predicted VaR (95% confidence): -0.0007155124330893159\n",
            "Real VaR (95% confidence): -0.0006554247112944722\n",
            "Mean Absolute Percentage Error (MAPE): 0.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Model Eval"
      ],
      "metadata": {
        "id": "z3rf0gx8CH9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_Transformer(nn.Module):\n",
        "    def __init__(self, n_layers, tr_layers, n_heads_first, n_heads_second, input_dim, hidden_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.tr_layers = tr_layers\n",
        "        self.n_heads_first = n_heads_first\n",
        "        self.n_heads_second = n_heads_second\n",
        "\n",
        "        self.weight_lstm = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        self.weight_transform = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        self.weight_transform2 = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        # self.weight_attn = nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "\n",
        "        # Initial fully connected layers to project input features\n",
        "        self.input_fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim * 2),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_dim * 2, hidden_dim),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # LSTM layers\n",
        "        self.main_task = nn.LSTM(input_size=hidden_dim,\n",
        "                                 hidden_size=hidden_dim,\n",
        "                                 batch_first=True,\n",
        "                                 num_layers=n_layers,\n",
        "                                 dropout=dropout)\n",
        "\n",
        "        self.last_task = nn.LSTM(input_size=hidden_dim,\n",
        "                                 hidden_size=hidden_dim,\n",
        "                                 batch_first=True,\n",
        "                                 num_layers=n_layers,\n",
        "                                 dropout=dropout)\n",
        "\n",
        "        # Transformer layers\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=self.n_heads_first,\n",
        "                                                        dim_feedforward=hidden_dim * 4,\n",
        "                                                        dropout=dropout,\n",
        "                                                        activation='relu',\n",
        "                                                        batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=self.tr_layers)\n",
        "\n",
        "        self.encoder_layer2 = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=self.n_heads_second,\n",
        "                                                         dim_feedforward=hidden_dim,\n",
        "                                                         dropout=dropout,\n",
        "                                                         activation='relu',\n",
        "                                                         batch_first=True)\n",
        "        self.transformer2 = nn.TransformerEncoder(self.encoder_layer2, num_layers=self.tr_layers)\n",
        "\n",
        "        # Final fully connected layer to project to output (next-minute close price)\n",
        "        self.output_fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 2, output_dim)\n",
        "        )\n",
        "\n",
        "    def generate_mask(self, size):\n",
        "        \"\"\"\n",
        "        Generate a causal mask for the Transformer, preventing future positions from attending to earlier positions.\n",
        "        \"\"\"\n",
        "        mask = torch.triu(torch.ones(size, size) * float('-inf'), diagonal=1)\n",
        "        return mask\n",
        "\n",
        "    def forward(self, input_vec):\n",
        "        # Pass through input FC layers\n",
        "        lstm_input = self.input_fc(input_vec)\n",
        "\n",
        "        # Generate mask for Transformer based on sequence length\n",
        "        seq_len,a = input_vec.size()\n",
        "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)  # Upper triangular mask\n",
        "        mask = mask.masked_fill(mask == 1, float('-inf'))  # Replace 1s with -inf for masking\n",
        "        transformer_output1 = self.transformer(lstm_input, mask=mask)\n",
        "        transformer_output2 = self.transformer2(lstm_input, mask=mask)\n",
        "\n",
        "        # LSTM layer\n",
        "        lstm_output, _ = self.main_task(lstm_input)\n",
        "\n",
        "        # Combine Transformer and LSTM outputs\n",
        "        lstm_output = self.weight_transform*transformer_output1 + self.weight_lstm*lstm_output + self.weight_transform2*transformer_output2\n",
        "        lstm_output /= (self.weight_lstm + self.weight_transform + self.weight_transform2)\n",
        "\n",
        "        # Pass through last LSTM layer\n",
        "        final_output, _ = self.last_task(lstm_output)\n",
        "\n",
        "        # Output layer for the predicted close price\n",
        "        output = self.output_fc(final_output)\n",
        "\n",
        "        return output.squeeze()"
      ],
      "metadata": {
        "id": "ATfDCJWrCGxj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle , time\n",
        "with open(\"final_model.pkl\", \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "start_time = time.time()\n",
        "evaluate_model(model)\n",
        "end_time = time.time()\n",
        "time_taken = end_time - start_time\n",
        "print(f\"Evaluation time: {time_taken:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeFo74OaChKb",
        "outputId": "772b9430-c430-428f-b8b0-920710ed5357"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 789.675891\n",
            "Test Loss as Percentage: 0.04%\n",
            "Predicted VaR (95% confidence): -0.0007364198099821806\n",
            "Real VaR (95% confidence): -0.0006554247112944722\n",
            "Mean Absolute Percentage Error (MAPE): 0.03%\n",
            "Evaluation time: 4.8712 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}